{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS-2 Lab-1 Scaffold.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p_v3u0tn4EH"
      },
      "source": [
        "# Lab 1: Decision trees Regression and Bagging\r\n",
        "### Univ.AI\r\n",
        "### ML-2 Cohort-1\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUkTNQKyouIA"
      },
      "source": [
        "The goal of this lab is to predict the winner of the 2016 Presidential election (Trump vs. Clinton) in each county in the US, measured as 'votergap' = (trump - clinton) in percentage points. <br>\r\n",
        "We do already know the answer to this now in 2021, but we intend to make a model to see how right or wrong our predictions are!\r\n",
        "\r\n",
        "To do this, we consider several predictors and model a decision tree to perform regression and predict the dependent variable 'votergap'.\r\n",
        "We then try to improve upon our simple Decision Tree model by implementing bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNb2qEmY9qrC"
      },
      "source": [
        "#Import libraries\r\n",
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.cm as cm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeRegressor\r\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\r\n",
        "from sklearn.utils import resample\r\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otueHZ1gxIl2"
      },
      "source": [
        "## Part 1:  Reading and Exploring the data\r\n",
        "\r\n",
        "We will be using 'county_level_election.csv' to model the outcome of the 2016 presidential election from various predictors.\r\n",
        "\r\n",
        "We start by reading in the datasets and visualizing the main predictors for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzAQ-k7BrsB6"
      },
      "source": [
        "#your code here\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmCAKsOb_z5h"
      },
      "source": [
        "Perform an 80-20 train-test split on the dataframe to get your training and test data. Take only the following features in 'X': 'population','hispanic','minority','female','unemployed','income','nodegree','bachelor','inactivity','obesity','density','cancer'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYmnE_GCsugd"
      },
      "source": [
        "#Split 80/20 train-test\r\n",
        "\r\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNQl7AVm2CzV"
      },
      "source": [
        "Consider 1 variable, say minority, and plot the relationship between minority and the dependent variable.\r\n",
        "\r\n",
        "Also plot this on a log scale to see if we can visualize it easier.\r\n",
        "\r\n",
        "\r\n",
        "Note: We chose minority as it has the highest correlation with our target variable, you can also see this by printing out the correlation matrix using `sns.heatmap()` <br>\r\n",
        "Remember not to leak any data while calculating the correlation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV-Q5W3d18Vk"
      },
      "source": [
        "#Plot minorty vs votergap\r\n",
        "#your code here\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SO8RdNc2zq_"
      },
      "source": [
        "#Plot log(minorty) vs votergap\r\n",
        "#your code here\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKmFxUkUxxXl"
      },
      "source": [
        "## Part 2: Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANwYZc255uLT"
      },
      "source": [
        "### 2.1: Fitting with 1 predictor\r\n",
        "\r\n",
        "First, let us fit, visualize, and interpret a tree with 1 predictor - minority.\r\n",
        "\r\n",
        "You will need to build a Decisition tree Regressor and plot their predictions of the training data with the actual train data as seen below.\r\n",
        "![goodreadsexample](https://drive.google.com/uc?export=view&id=1iTuS6SdohXYSzGm8hJYf1m4W3en0hIOt)\r\n",
        "\r\n",
        "\r\n",
        "As you can see from above, we have tried out various max_depth and min_samples_split. <br>\r\n",
        "Feel free to play around with sklearns DecisionTreeRegressor functions parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7sp-HXmuook"
      },
      "source": [
        "#your code here\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfsmaiR8W1K"
      },
      "source": [
        "### 2.2: Fitting with all predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3K26UhCF9T"
      },
      "source": [
        "Now, use all the predictors to model the Decision Tree.\r\n",
        "\r\n",
        "Print out the actual training set and their predictions and compare these values to see how well your model has done. Save this as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSfrHCSMLeGY"
      },
      "source": [
        "#your code here\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbunyb-L_W_4"
      },
      "source": [
        "Perform 5-fold cross-validation to determine what the best max_depth would be for a single regression tree using your entire training set and GridSearchCV().\r\n",
        "\r\n",
        "Next, visualize these results by plotting the mean CV score and +/- 2 standard deviations across the validation sets.<br>\r\n",
        "To do this, you will need to store the training scores, mean and standard deviations of the test score.\r\n",
        "\r\n",
        "Your plot should look something like this: \r\n",
        "\r\n",
        "![goodreadsexample](https://drive.google.com/uc?export=view&id=1iAJf3AGbiri8r6B0nrtbRIgxhkF1yGsR)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfPOii9a_WVX"
      },
      "source": [
        "depths = list(range(1, 21))\r\n",
        "\r\n",
        "#your code here\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNeD_yfpCxl3"
      },
      "source": [
        "# plot means and shade the 2 SD interval\r\n",
        "\r\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A25UpJPNEHJU"
      },
      "source": [
        "Choose the best max_depth based on the result of your cross validation and build your final model with all predictors and the optimal max_depth.<br>\r\n",
        "Also print out the mean accuracy on the train and test data using the `score()` method from the DecisionTreeRegressor class.\r\n",
        "\r\n",
        "**You can add pruning or any other techniques you have learnt in the lectures till now.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C_tOzVqEK7e"
      },
      "source": [
        "#your code here\r\n",
        "\r\n",
        "\r\n",
        "print(\"Train accuracy:\")\r\n",
        "print(\"Test accuracy:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNqdI3t5x0rx"
      },
      "source": [
        "## Part 3: Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR82wMUZEY9L"
      },
      "source": [
        "You might still be overfitting in your previous model, we can now attempt to reduce the overfitting by implementing bagging. <br>\r\n",
        "In this lab, we will be performing bagging for a decision tree modeled only on a single predictor as it is easier to visualize.\r\n",
        "\r\n",
        "To do this, you will need to first bootstrap (resample data) and aggregate over all of the bootstrapped models. <br>\r\n",
        "Plot your bagged models predictions in the training set along with the actual full training set to observe the predictions of your bagged models. <br>\r\n",
        "\r\n",
        "Try implementing this without using sklearns `BaggingRegressor()`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVh_r1hyIxi7"
      },
      "source": [
        "### 3.1: Bagging with 1 predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-J5M7nRFLhm"
      },
      "source": [
        "#your code here\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNt5obduL7Bm"
      },
      "source": [
        "#Plot the actual train data vs your bagged models predictions on the train data\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SLNozs5I4MX"
      },
      "source": [
        "### 3.2: Bagging with all predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WVCxVaI_Y2"
      },
      "source": [
        "Perform the same operations as you did above, except this time with all the predictors. \r\n",
        "In addition to this, calculate the average score of all of the individual trees and plot a histogram of the same. <br>\r\n",
        "![goodreadsexample](https://drive.google.com/uc?export=view&id=1qBk8TMOygnIDmUCSzpkrrH7N0ulOrHSr)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Also print and calculate the score of the aggregated trees.\r\n",
        "\r\n",
        "You need not plot the training set and their predictions as it gets harder to visualize so many dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngIUKC4gFNCD"
      },
      "source": [
        "#your code here\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXxGok48MEpM"
      },
      "source": [
        "#Print and plot a histogram of the average R-squared score of all of the individual trees \r\n",
        "#your code here\r\n",
        "\r\n",
        "#Print and calculate the R-squared score of the aggregated trees\r\n",
        "#your code here\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PfhWn21IVWW"
      },
      "source": [
        "Question: What do you observe from the above histogram and the aAverage R-squared score of the individual trees and the R-squared score of the aggregated trees?\r\n",
        "\r\n",
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9IkHAZNJ_ca"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
